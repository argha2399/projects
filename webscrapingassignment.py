# -*- coding: utf-8 -*-
"""WebScrapingAssignment

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bg1pY3Hl2oUHDUKWCz2IlButGXKoc2ZN
"""

import pandas as pd
from bs4 import BeautifulSoup
import requests
import html5lib
import warnings
warnings.filterwarnings('ignore')
url = 'https://www.google.com/search?q='
query = 'domain%20name%20availability'

def get_google_results(link, path):
    
    n_results = 100
    response = requests.get(f'{link}+{path}&num={n_results}')
    soup = BeautifulSoup(response.content, 'html5lib')

    div = soup.find_all('div', class_="BNeawe vvjwJb AP7Wnd")
    description = []
    for i in div:
        description.append(i.getText())
    #print(description)

    from urllib.parse import urlparse


    site = soup.find_all('div',class_="egMi0 kCrYT")
    link = []
    for i in site:
        url = i.find('a')['href']

        split_link = url.split('=')[1].split('&')[0]
        link.append(split_link)
    #print(link)

    div3 = soup.find_all('div',class_="BNeawe UPmit AP7Wnd lRVwie")
    domains = []
    for i in div3:

        domain1 = i.text.split('>')[0]
        domain2 = domain1.split('â€º')[0]
        try:
            domain3 = domain2.split('www.')[1]
        except:
            domain3 = domain2
        domains.append(domain3)
    #print(domains)


    data = pd.DataFrame({'Domains':domains, 'Link': link , 'Description': description})
    #print(data)
    return data

url = 'https://www.google.com/search?q='
query = 'domain%20name%20availability'
get_google_results(url, query)

!pip install mysql-connector-python

import mysql.connector

mydb = mysql.connector.connect(
  host="localhost",
  user="root",
  password="Sengupta@25"
)

print(mydb)

!pip install sqlalchemy

!pip install mysqlclient

from sqlalchemy import create_engine
from urllib.parse import quote_plus
my_conn = create_engine('mysql+mysqldb://root:%s@localhost/Worksheet' % quote_plus('Sengupta@25'))

data.to_sql(con = my_conn, name = 'Domain_Name_Availability', if_exists = 'append', index = True)









